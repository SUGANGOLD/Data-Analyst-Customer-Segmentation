{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensuring plots display inline in Jupyter Notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Loading the Customer Address Data\n",
    "cust_address = pd.read_excel('Raw_data.xlsx', sheet_name='CustomerAddress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   customer_id         3999 non-null   int64 \n",
      " 1   address             3999 non-null   object\n",
      " 2   postcode            3999 non-null   int64 \n",
      " 3   state               3999 non-null   object\n",
      " 4   country             3999 non-null   object\n",
      " 5   property_valuation  3999 non-null   int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 187.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Exploring the dataset information\n",
    "cust_address.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types of the columns look fine. Let's now assess the data quality and apply a data cleaning process wherever necessary to prepare the dataset for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 3999\n",
      "Total columns: 6\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Displaying total records and columns\n",
    "print(f\"Total records: {cust_address.shape[0]}\")\n",
    "print(f\"Total columns: {cust_address.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric Columns and Non-Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['customer_id' 'postcode' 'property_valuation']\n",
      "Non-numeric columns: ['address' 'state' 'country']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Identifying numeric and non-numeric columns\n",
    "df_numeric = cust_address.select_dtypes(include=[np.number])\n",
    "df_non_numeric = cust_address.select_dtypes(exclude=[np.number])\n",
    "print(f\"Numeric columns: {df_numeric.columns.values}\")\n",
    "print(f\"Non-numeric columns: {df_non_numeric.columns.values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Missing Values Check\n",
    "\n",
    "Checking for the presence of missing values in the dataset. If missing values are present for a particular feature, then depending on the situation, the feature may either be dropped (in cases where a significant amount of data is missing) or an appropriate value will be imputed in the feature column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "customer_id           0\n",
      "address               0\n",
      "postcode              0\n",
      "state                 0\n",
      "country               0\n",
      "property_valuation    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Checking for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "print(cust_address.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the datase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2. Inconsistency Check in Data\n",
    "\n",
    "We will check for inconsistencies or typographical errors in the categorical columns. The columns to be checked are 'address', 'postcode', 'state', and 'country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'state' column before standardization:\n",
      "state\n",
      "NSW                2054\n",
      "VIC                 939\n",
      "QLD                 838\n",
      "New South Wales      86\n",
      "Victoria             82\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Checking for inconsistencies in 'state' column\n",
    "print(\"Unique values in 'state' column before standardization:\")\n",
    "print(cust_address['state'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are inconsistencies in the 'state' column. For New South Wales and Victoria, both the full names and abbreviations are present. To standardize the state names, 'New South Wales' will be replaced with 'NSW', and 'Victoria' will be replaced with 'VIC'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Standardizing state names to maintain consistency\n",
    "state_mapping = {'New South Wales': 'NSW', 'Victoria': 'VIC'}\n",
    "cust_address['state'] = cust_address['state'].replace(state_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the function, the state names have been standardized, and there are no inconsistencies in the 'state' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'state' column after standardization:\n",
      "state\n",
      "NSW    2140\n",
      "VIC    1021\n",
      "QLD     838\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Verifying changes to the 'state' column after standardization\n",
    "print(\"Unique values in 'state' column after standardization:\")\n",
    "print(cust_address['state'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "Australia    3999\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_address['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no inconsistencies in the 'country' column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Postcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'postcode' column looks perfect. There are no inconsistencies or typographical errors in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>060 Morning Avenue</td>\n",
       "      <td>2016</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6 Meadow Vale Court</td>\n",
       "      <td>2153</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0 Holy Cross Court</td>\n",
       "      <td>4211</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17979 Del Mar Point</td>\n",
       "      <td>2448</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9 Oakridge Court</td>\n",
       "      <td>3216</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>1482 Hauk Trail</td>\n",
       "      <td>3064</td>\n",
       "      <td>VIC</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>57042 Village Green Point</td>\n",
       "      <td>4511</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>87 Crescent Oaks Alley</td>\n",
       "      <td>2756</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>8194 Lien Street</td>\n",
       "      <td>4032</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>320 Acker Drive</td>\n",
       "      <td>2251</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        address  postcode state    country\n",
       "0            060 Morning Avenue      2016   NSW  Australia\n",
       "1           6 Meadow Vale Court      2153   NSW  Australia\n",
       "2            0 Holy Cross Court      4211   QLD  Australia\n",
       "3           17979 Del Mar Point      2448   NSW  Australia\n",
       "4              9 Oakridge Court      3216   VIC  Australia\n",
       "...                         ...       ...   ...        ...\n",
       "3994            1482 Hauk Trail      3064   VIC  Australia\n",
       "3995  57042 Village Green Point      4511   QLD  Australia\n",
       "3996     87 Crescent Oaks Alley      2756   NSW  Australia\n",
       "3997           8194 Lien Street      4032   QLD  Australia\n",
       "3998            320 Acker Drive      2251   NSW  Australia\n",
       "\n",
       "[3999 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust_address[['address', 'postcode', 'state', 'country']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Duplication Checks\n",
    "We need to ensure that there are no duplicate records in the dataset, as duplicates can lead to errors in data analysis due to poor data quality. If there are duplicate rows, we will need to drop those records.\n",
    "\n",
    "To check for duplicate records, we first need to remove the primary key column from the dataset, and then we can apply the drop_duplicates() function provided by Python.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after removing customer_id (pk), duplicates : 3999\n",
      "Number of records in origial dataset : 3999\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Dropping duplicates based on address-related columns (excluding customer_id)\n",
    "cust_address_dedupped = cust_address.drop('customer_id', axis=1).drop_duplicates()\n",
    "print(f\"Records after deduplication: {cust_address_dedupped.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both numbers are the same, there are no duplicate records in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exporting the Cleaned Customer Demographic Dataset to CSV\n",
    "The customer address dataset is now clean. Therefore, we can export the data to a CSV file to continue our analysis of customer segments by joining it with other tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Exporting the cleaned data to a CSV file\n",
    "cust_address.to_csv('CustomerAddress_Cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Checking for Master-Detail Record Counts \n",
    "\n",
    "We will check the master table (CustomerDemographic_Cleaned), which contains the entire customer data, for the Customer IDs that are being dropped from the customer address dataset.\n",
    "\n",
    "These Customer IDs belong to customers who have an address but are not part of the demographics dataset yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Loading the demographic data and verifying customer IDs against address data\n",
    "cust_demo_detail = pd.read_csv('CustomerDemographic_Cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>DOB</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Laraine</td>\n",
       "      <td>Medendorp</td>\n",
       "      <td>Female</td>\n",
       "      <td>93</td>\n",
       "      <td>1953-10-12</td>\n",
       "      <td>Executive Secretary</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Eli</td>\n",
       "      <td>Bockman</td>\n",
       "      <td>Male</td>\n",
       "      <td>81</td>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>Administrative Officer</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Arlin</td>\n",
       "      <td>Dearle</td>\n",
       "      <td>Male</td>\n",
       "      <td>61</td>\n",
       "      <td>1954-01-20</td>\n",
       "      <td>Recruiting Manager</td>\n",
       "      <td>Property</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Talbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>1961-10-03</td>\n",
       "      <td>Missing</td>\n",
       "      <td>IT</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sheila-kathryn</td>\n",
       "      <td>Calton</td>\n",
       "      <td>Female</td>\n",
       "      <td>56</td>\n",
       "      <td>1977-05-13</td>\n",
       "      <td>Senior Editor</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id      first_name  last_name  gender  \\\n",
       "0            1         Laraine  Medendorp  Female   \n",
       "1            2             Eli    Bockman    Male   \n",
       "2            3           Arlin     Dearle    Male   \n",
       "3            4          Talbot        NaN    Male   \n",
       "4            5  Sheila-kathryn     Calton  Female   \n",
       "\n",
       "   past_3_years_bike_related_purchases         DOB               job_title  \\\n",
       "0                                   93  1953-10-12     Executive Secretary   \n",
       "1                                   81  1980-12-16  Administrative Officer   \n",
       "2                                   61  1954-01-20      Recruiting Manager   \n",
       "3                                   33  1961-10-03                 Missing   \n",
       "4                                   56  1977-05-13           Senior Editor   \n",
       "\n",
       "  job_industry_category     wealth_segment deceased_indicator owns_car  \\\n",
       "0                Health      Mass Customer                  N      Yes   \n",
       "1    Financial Services      Mass Customer                  N      Yes   \n",
       "2              Property      Mass Customer                  N      Yes   \n",
       "3                    IT      Mass Customer                  N       No   \n",
       "4               Missing  Affluent Customer                  N      Yes   \n",
       "\n",
       "   tenure  Age  \n",
       "0    11.0   70  \n",
       "1    16.0   43  \n",
       "2    15.0   70  \n",
       "3     7.0   62  \n",
       "4     8.0   47  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 12: Comparing master-detail record counts\n",
    "print(f\"Total Records in Demographic Table: {cust_demo_detail.shape[0]}\")\n",
    "print(f\"Total Records in Address Table: {cust_address.shape[0]}\")\n",
    "print(f\"In Demographic Table {cust_address.shape[0] - cust_demo_detail.shape[0]} records are getting dropped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>address</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>property_valuation</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>past_3_years_bike_related_purchases</th>\n",
       "      <th>DOB</th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_industry_category</th>\n",
       "      <th>wealth_segment</th>\n",
       "      <th>deceased_indicator</th>\n",
       "      <th>owns_car</th>\n",
       "      <th>tenure</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>060 Morning Avenue</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Laraine</td>\n",
       "      <td>Medendorp</td>\n",
       "      <td>Female</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1953-10-12</td>\n",
       "      <td>Executive Secretary</td>\n",
       "      <td>Health</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6 Meadow Vale Court</td>\n",
       "      <td>2153.0</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Eli</td>\n",
       "      <td>Bockman</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>Administrative Officer</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arlin</td>\n",
       "      <td>Dearle</td>\n",
       "      <td>Male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1954-01-20</td>\n",
       "      <td>Recruiting Manager</td>\n",
       "      <td>Property</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0 Holy Cross Court</td>\n",
       "      <td>4211.0</td>\n",
       "      <td>QLD</td>\n",
       "      <td>Australia</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Talbot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1961-10-03</td>\n",
       "      <td>Missing</td>\n",
       "      <td>IT</td>\n",
       "      <td>Mass Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>No</td>\n",
       "      <td>7.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17979 Del Mar Point</td>\n",
       "      <td>2448.0</td>\n",
       "      <td>NSW</td>\n",
       "      <td>Australia</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sheila-kathryn</td>\n",
       "      <td>Calton</td>\n",
       "      <td>Female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1977-05-13</td>\n",
       "      <td>Senior Editor</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Affluent Customer</td>\n",
       "      <td>N</td>\n",
       "      <td>Yes</td>\n",
       "      <td>8.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id              address  postcode state    country  \\\n",
       "0            1   060 Morning Avenue    2016.0   NSW  Australia   \n",
       "1            2  6 Meadow Vale Court    2153.0   NSW  Australia   \n",
       "2            3                  NaN       NaN   NaN        NaN   \n",
       "3            4   0 Holy Cross Court    4211.0   QLD  Australia   \n",
       "4            5  17979 Del Mar Point    2448.0   NSW  Australia   \n",
       "\n",
       "   property_valuation      first_name  last_name  gender  \\\n",
       "0                10.0         Laraine  Medendorp  Female   \n",
       "1                10.0             Eli    Bockman    Male   \n",
       "2                 NaN           Arlin     Dearle    Male   \n",
       "3                 9.0          Talbot        NaN    Male   \n",
       "4                 4.0  Sheila-kathryn     Calton  Female   \n",
       "\n",
       "   past_3_years_bike_related_purchases         DOB               job_title  \\\n",
       "0                                 93.0  1953-10-12     Executive Secretary   \n",
       "1                                 81.0  1980-12-16  Administrative Officer   \n",
       "2                                 61.0  1954-01-20      Recruiting Manager   \n",
       "3                                 33.0  1961-10-03                 Missing   \n",
       "4                                 56.0  1977-05-13           Senior Editor   \n",
       "\n",
       "  job_industry_category     wealth_segment deceased_indicator owns_car  \\\n",
       "0                Health      Mass Customer                  N      Yes   \n",
       "1    Financial Services      Mass Customer                  N      Yes   \n",
       "2              Property      Mass Customer                  N      Yes   \n",
       "3                    IT      Mass Customer                  N       No   \n",
       "4               Missing  Affluent Customer                  N      Yes   \n",
       "\n",
       "   tenure   Age  \n",
       "0    11.0  70.0  \n",
       "1    16.0  43.0  \n",
       "2    15.0  70.0  \n",
       "3     7.0  62.0  \n",
       "4     8.0  47.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 13: Identifying customer IDs missing in demographic data using an outer join\n",
    "\n",
    "# Perform an outer join on the 'customer_id' column between the customer address and demographic detail datasets\n",
    "cust_drop = cust_address.merge(cust_demo_detail, on='customer_id', how='outer', indicator=True)\n",
    "\n",
    "# Print the customer IDs that are not present in both datasets\n",
    "print(\"Customer IDs not present in both datasets:\")\n",
    "print(cust_drop[cust_drop['_merge'] != 'both'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
